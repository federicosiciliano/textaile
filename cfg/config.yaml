
data:
    #name: [Proto_textiles,Proto_color_palette.csv]
    #name: [VA_textiles_padded_inner,color_palette_va_inner.csv]
    name: [MET_textiles_padded_inner,color_palette_met_inner.csv]
    source: local #uci #tfds #custom #path_to_local_file
    local_key: ["x","y"]
    /loader_params:
      # Proto_textiles: {}
      # Proto_color_palette.csv:
      #   delimiter: ";"
      # VA_textiles_padded_inner: {}
      # color_palette_va_inner.csv:
      #   delimiter: ","
      MET_textiles_padded_inner: {}
      color_palette_met_inner.csv:
        delimiter: ","
    custom_data_functions:
      -
        -function:
          value: data_utils.utils.sort_by_column
          eval: eval
        kwargs:
          column_dict:
            y: 0
      -
        -function:
          value: data_utils.utils.separate_rows_and_columns
          eval: eval
        kwargs:
          row_separate_keys:
            y: [concept_names]
          row_ids:
            concept_names: [0]
          column_separate_keys:
            y: [image_id]
          column_ids:
            image_id: [0]
      # -
      #   -function:
      #     value: data_utils.utils.nan_to_num
      #     eval: eval
      #   kwargs:
      #     fill_dict:
      #       y:
      #         nan: -1
      - # move channel dimension from the end to the second position
        -function:
          value: data_utils.utils.transpose
          eval: eval
        kwargs:
          swap_dict:
            x: [0,3,1,2]
      -
        -function:
          value: data_utils.utils.min_max_scale
          eval: eval
        kwargs:
          scale_dict:
            x: [0,255]
            -y:
              value: np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[360,100,100,360,100,100,360,100,100,360,100,100,360,100,100,1,1,1,1,1,1]])
              eval: eval

    merge_before_split: False
    # merge_keys:
    #   "x": ["train_x", "val_x", "test_x"]
    #   "y": ["train_y", "val_y", "test_y"]
    # -concat_function:
    #     value: np.concatenate
    #     eval: eval
    # del_after_merge: True
    
    split_keys:
      "x": ["train_x", "val_x", "test_x"]
      "y": ["train_y", "val_y", "test_y"]
    # train_sizes: [200, 100] #change for prototyping
    # test_sizes: [100, 100] #defines validation test set as first arg and sampled from training set,
    test_sizes: [0.1, 0.1] #defines validation test set as first arg and sampled from training set,
    #test set taken from another set of inputs downloaded
      #int: number of samples, float: percentage of samples
      #all values are relative to remaining data after each split
    # train_sizes: None #not needed, unless you need less data in training after test split
    split_random_state: 21094
    # split_shuffle: True
    # split_stratify: None
    del_after_split: True
    
    # scaling_method: None
    # scaling_params: {}
    # scaling_keys: ["train_x", "val_x", "test_x"] #first one is the one used for fit
    # scaling_fit_params: {}
    # scaling_transform_params: [{},{},{}]

    one_hot_encode: False
    # onehotencoder_params:
    #     handle_unknown: ignore
    #     sparse: False

    #scaling: MinMax #None #Standard #MinMax
    
+model: textaile #cnn

#EXPERIMENT PARAMETERS - NOT SAVED AS PART OF THE CONFIGURATION
__exp__:
    name: provaSemplice #name of the experiment, optional, default = "experiment_name"
    # project_folder: ../ #project folder, used to locate folders, optional, default = "../"
    # key_len: 16 #Length of experiment key, optional, default = 16
    # key_prefix: "" #Prefix for experiment key, optional, default = ""
    __imports__: #imports needed for config preparation (e.g. type casting)
      - data_utils
      - torch
      - torchvision
      - numpy as np
      # - name: pandas #" as " will be recognized
      #   fromlist:
      #     - DataFrame
      #   as:
      #     - DF